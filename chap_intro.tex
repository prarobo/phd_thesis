% This file (dissertation-main.tex) is the main file for a dissertation.
\documentclass {udthesis}
% preamble

% Include graphicx package for the example image used
% Use LaTeX->PDF if including graphics such as .jpg, .png or .pdf.
% Use LaTeX->PS->PDF if including graphics such as .ps or .eps
% Best practice to not specify the file extension for included images,
% so when LaTeX is building it will look for the appropriate image type.
\usepackage{graphicx}
\usepackage[acronym]{glossaries}
\usepackage[inline]{enumitem}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{url}
\usepackage{booktabs}
\usepackage{tikz}
\usetikzlibrary{matrix,shapes,arrows,positioning,chains}
\usepackage{threeparttable}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{multicol}
\usepackage[export]{adjustbox}

\include{acronym_list}

\makeglossaries
\graphicspath{{fig/}}

\begin{document}

%=========================================================================================
% Introduction

\chapter{Introduction}
\label{chap:thesis_intro}

%=========================================================================================
\section{Outline}

\begin{enumerate}[label=Chapter \arabic*:]
  \item If robotic systems are to decrease the strain on human workforce, they need to be autonomous; 
  perception and data interpretation with in-built robustness to noise are central to autonomy. 

  \begin{enumerate}[label=Section \arabic*:, start=0]
  \item Intro

  \item Robotics systems are beneficial for handling tasks characterized as dull, dirty and dangerous for humans.
  
    \begin{enumerate}[label=Para \arabic*:, start=1]
       
      \item Robotics systems are beneficial in environments hazardous or inaccessible to humans like war zones, nuclear radiation prone regions, and deep sea.
      
      \item When the reasoning ability and intelligence of a human expert is sometimes deemed necessary to deal with various elements in a potentially inhospitable environment, robots can still be tele-operated by human operators.
      
    \end{enumerate}

  \item Unmanned aerial, ground and underwater vehicles mostly rely on human decision making via teleoperation while working in natural environments.
  
    \begin{enumerate}[label=Para \arabic*:, start=1]
    
      \item Tele-operation allows for a human operator to make decision for a robot in real-time.
      
      \item Though tele-operation solution can combine the durability of a robotic agent and intellect of a human, it has to deal with sometimes unreliable communication links and constant need for human attention.

      \item Automated decision making is essential for robots that do not have a human operator.
	\end{enumerate}
	    
  \item To make informed automated decisions, robotic systems need to sense and interpret the state of their environments.

    \begin{enumerate}[label=Para \arabic*:, start=1]

      \item Sensors allow a robotic system to gather data about its environment.
      
      \item Interpreting the state of an environment involves identifying objects and gaining a semantic undestanding of different elements in the environment.
            
      \item Knowing the state of the environment is essential to make \emph{informed} automated decisions.
      
    \end{enumerate}
                    
  \item The capability of a robot to image and label objects in its surroundings, or in other words do object recognition, is more challenging in unstructured natural environments than in man-made environments.
  
    \begin{enumerate}[label=Para \arabic*:, start=1]
      \item Robots in the past have been specialized to do tasks in well defined environments like assembly lines  where environmental variables like visibility and lighting can be controlled.      
      
      \item In natural environments, despite the its unstructured nature and unpredictable variations in environmental conditions, a robot needs to understand and parse the environment into labeled objects.
      
      \item To work in natural environments, the object recognition capabilities of robotic system needs to be robust to noise and variations in  environmental conditions.
      
    \end{enumerate}

  \item Noise in sensor data obtained in natural environments limits the amount of useful information that can be extracted for the object recognition process.
    
    \begin{enumerate}[label=Subsection \arabic*:, start=1]
      \item The sources of noise associated with an application need to be carefully analyzed before designing appropriate filters to mitigate the noise.
      
      \begin{enumerate}[label=Para \arabic*:, start=1]
	
	\item Noise can enter sensor data through several forms, for example the noise in a camera sensor can be sub-divided as: noise inherent to the sensor, noise due to the setup associated with data collection and noise introduced by the environment.
	
	\item To understand the noise inherent to a sensor, as an example, the various noise sources in a camera sensor can be analyzed.
	
	\item Noise can be introduced by the data-collection setup, in form of movement or vibration of the sensing apparatus.
	
	\item Environmental conditions can themselves be sources of noise, in the context of an underwater camera, this can be in form of poor lighting, light absorption by water or scattering from suspended particles in water.
	
	\item A method that is designed to work in natural environments, requires dedicated effort to filter noise to get useful information from sensor data.
	
      \end{enumerate}
    
      \item Once the noise sources are analyzed, dedicated filters, some specialized for the sensing apparatus and others specialized for the sensing environment need to be designed as a part of the object recognition procedure.

      \begin{enumerate}[label=Para \arabic*:, start=1]
        
        \item Filters that deal with a specific sensing apparatus are required to work with the noise generated by the sensor.
        
	\item Specialized filters are required to deal with the noise from the environment conditions that robot will be exposed to.
	
	\item Analyzing and filtering noise is an important component of object recognition systems that work in natural environments.
    
      \end{enumerate}
      
    \end{enumerate}

  \item Existing object recognition methods do not generally translate from one application domain to another.
    
    \begin{enumerate}[label=Para \arabic*:, start=1]
      
      \item Since object recognition is a challenging problem, researchers often specialize their object recognition modules to work in specific controlled environments to optimize performance.
      
      \item Object recognition methods designed for specific controlled environments do not fare well with wide variations in environmental conditions.
      
      \item Porting an object recognition method specialized for a specific environment condition to work on an entirely different application with drastically different environmental conditions can be a laborious process and might no longer offer the previous levels of performance.
          
    \end{enumerate}

  \item To work in natural environments, the object recognition process should be robust and sufficiently general to deal with various kinds of objects.
  
    \begin{enumerate}[label=Para \arabic*:, start=1]
      \item To work in natural environments with unpredictable conditions, the object recognition techniques should be robust to noise and variations in environmental conditions.
      
      \item Multi-layered object recognition frameworks with dedicated modules for dealing with different sub-problems like filtering and hypothesis testing allow easy customization of layers based on application requirements.
      
      \item Layered Object recognition frameworks designed for natural environments with inbuilt robustness to variations in environmental conditions can be easily ported to a multitude of applications. 
      
    \end{enumerate}
  
  \item Object recognition is central to building robots capable of automated and informed decision making, and thus achieving full autonomy; especially while operating in noisy natural environments.

    \begin{enumerate}[label=Para \arabic*:, start=1]
      
      \item Object recognition capability allows a robot to interpret its environment.
      
      \item Informed decision making  comprises using information about the state of the environment to making decisions.
      
      \item Noisy natural environments pose a challenge to object recognition and hence dealing with noise is critical for a robotic system the depend on object recognition to make automated decisions.
      
      \item Robust object recognition capabilities translates to autonomous decision making, this combined with autonomous actuation
      results in full robot autonomy.

    \end{enumerate}
    
\end{enumerate}
\end{enumerate}

%================================================================================================================
\section{Benefits of Robotic Systems}

Robotic systems are beneficial for tasks that come under the purview of the \emph{3-D}'s--dirty, dull and dangerous. Currently manufacturing and assembly lines where tasks of repititive nature, otherwise considered dull, are places where robotic systems are ubiquitous. Tasks like traversing tunnels and sewer, dirty in nature, are being delegated to teleoperated-robots. The other avenue where robotic systems are being promoted relate to activities deemed dangerous for humans like deep sea exploration, operation in radiation prone zones, or war zones. With enabling new advances in the field of robotics, robots are beginning to take over new roles to complement and assist humans in various ways.

Though advances in robotic systems have enabled robots to outperform humans in certain specialized tasks like competing in 
games like Go \cite{deepmind} and Chess \cite{deepblue}, robotic systems still lack the ability to reason and operate
autonomously in most unpredictable real world environments. 
In such cases a human expert is deemed necessary to reason for the robot and guide the machine
to accomplish its objectives. This case of tele-operation of robots by humans is seen a solution to accomplish
tasks in inhospitable environments without exposing humans to risk. Some prime examples of such remote operation in
dangerous enviroments include the rescue and repair effort at radiation affected zones in Fukushima Daichii nuclear power plant \cite{fukushima} or remotely operated weapons like Packbot \cite{packbot} and Predator \cite{predator} deployed
at war zones in Iraq and Afganistan. Though tele-operation appears to offer a solution, a more scalable alternative
is aiming for full autonomy of robotic systems to minimize the strain on human workforce.

%================================================================================================================
\section{Tele-operation Solutions}

Tele-operation is widely prevalent in robots as it offers an avenue for humans to leverage the benefits posed by robotic system to perform activities 
that are \emph{dirty} or \emph{dangerous} without being physically present on the site of operation. During tele-operation, the human operator 
typically operates the robot from a safe distance away from the point of activity of the robot. This safe distance could range from a few meters to over a few hundered kilometers based on the nature of the activity. For instance in case of a tunnel or sewer inspection, the operator can stay a few meters outside the structure and drive a robot that is present inside the structure. On the other hand, in case of weaponized drones like the predator \cite{predator} that operate in war zones, the operator typically controls the drone from a safe remote command center a few hundred kilometers from the point of action of the drone. Tele-operation allows the operator to consume the sensory information collected by the robot and make \emph{informed decisions} for the robot. The robot then the translates \emph{informed decision} into a sequence of actions. The tele-operation solution allows a human operator to safely accomplish his or her objective 
without being in state of phiysical discomfort or harm. 

Tele-operation allows the durability of a robotic agent and intellect of a human to provide a powerful solution to solve problems ranging from deep sea exploration to safe operation in combat zones. Despite the attractiveness of the tele-operation solution, it still requires constant attention from
a human operator. Additionally, since the human operator is not present on site during tele-operation, a reliable communication channel is essential to remotely control the robot. If the communication links are unreliable, or if it could potentially be wilfully sabotaged by the enemy in a warzone, it could potentially lead to disconnection of the robotic system from the human operator and could possibly result is catastrophic failure of the robot. The constant need for a human operator and the need to reliable communication channels are two shortcoming that plague tele-operated systems.

If the objective is to move towards decreasing the strain on the human workforce, it is imperative to decrease the reliance of robots on humans for operation. Building sutonomy into robotic systems also overcomes the need for reliable communication channels. If the robot is capable of making decisions without any guidance from an external source, the need for constant communication is no longer a requirement.
Thus improving the cognitive capabilities to enable atomated decision making is essential to build robust self-sufficient robotic systems.

%================================================================================================================
\section{Components of Informed Automated Decision Making}

The first component of informed decision making is gathering the information needed to make a decision. For robotic system
information about the environment dictates the descisions it makes. Collecting sensory data is the prime 
and often the only mechanism available for a robot to lean about its environment. Based on the sensors availabe to a 
robotic system different aspects of the environment can be captured this raw sensor data needs to processed
to get usable information that enable a robot to reson about the state of its environment. An informed decision is 
nothing but extrapolation of the reasoning process to choose an action from the set of actions available to an agent.
If the entire sequence of sensory data aggregation to choosing an action based on processed information is performed by
the robotic system without any external intervention, the due process can be described as automated decision making. 

Transforming the sensory data into usable information involves parsing the data to gain a semantic understanding about the state of the environment.
The basic stage of understanding a scene is separation and labeling of different objects present.
A more refined version of this understanding is deciphering the relationship and interplay between the specific objects in the scene.
Such a detailed semantic understanding allows a robot to infer the ability of the componets of the scene to affect its 
ability to perform a certain task.

The ability of a robot to detect and label objects in its environment is an important step towards gaining semantic understanding of its environment.
Since semantic understanding of a scene dictates the ability of a robotic system to make informed decisions, object recognition capability
is central to automated informed descision making.

%================================================================================================================
\section{Automated Decision Making in Natural Environment}

Building robotic systems that are fully autonomous with an ability to perform actions based on their observations is open problem.
The existing solutions typically apply ony to certain specialized domains. Before further on this regard, it is important to
understand that natural environments pose significant challenges that compound the problems faced by robotic systems.
The first part of this section, the definion of natural environment in the context of this dissertation is stated (in Section~\ref{sec:nat_environ_def}).
The following Section~\ref{sec:robots_nat_environ} goes into the details on the challenges faced by robotic systems in natural environments.


\subsection{Natural Environment}
\label{sec:nat_environ_def}

The word Natural Environments in this dissertation refers to uncontrolled real world  environments depicting scenes containing
predominantly naturally ocurring objects where the robot has 
no direct control over any environment variable. However we assume that the robot can use accessories like artificial light sources attached 
to it to influence the state of the environment and enhance sensor measurements. Due to the wide variability in natural environments, 
it is challenging to model such environments.
The task of modeling gets further complicated in the presence of unpredictable levels of noise. Thus, in this disseration, we refer to real world
environments that are challenging to model due to the unpredictability in the environment parameters and unpredictability of noise in measurements as natural environments. 
According to this definition, deep sea or forest landscapes with vegetation are some prime examples that come under the defined category of natural environments.


\subsection{Robotic Systems in Natural Environments}
\label{sec:robots_nat_environ}

Robots in the past, till current day, have been specialized to do tasks in well defined environments like assembly lines where environmental variables like visibility and lighting are strictly controlled. While such environment variable are known in advance, a mathematical model depicting the environment 
can be generated to map the robot actions to all possible environment states. In such cases, based on the state of the environment observed, a robot action was choosen from the list of available actions in accordance with a database of logical rules. Systems that operated on this principle, \emph{Expert Systems} 
\cite{russel} came into existence in 1980's. Such systems fail in scenarios where the environment cannot be perfectly modeled. Despite the advances in field of robotics since the time of Expert Systems, robotics systems still face challenges when dealing with unpredictable environments in the likes of natural settings seen in forests or deep sea.

The task of understanding natural scenes and recognizing objects like animals from them is shown to be a cognitively challenging task 
even for humans \cite{wichmann}. The unstructured nature and unpredictability associated with natural environment makes the task of 
building models to capture natural scenes is challenging.
Using global features to characterize the nature of a scene is shown to be possible \cite{olivia}. However these models can only offer a high level understanding
of the scene. For instance, the high level understanding translates to differentiating widely different scenes like a beach, foliage or a busy city street. It does not talk about separating the different components in the scenes. Most object recognition techniques depend on features like edges and textures to identify objects. Such approach are difficult to implement in scenes from natural environments where the edges of objects can be difficult to distinguish.
The noise in sensor measurement in such natural scenes could further complicated the object recognition task. Thus, for a robotic system to 
successful in making automated informed descisions in natural environments, it has to possess robust object recognition capabilities
that are robust to noise and can handle variations in environmental conditions.

The challenges associated with object recognition in natural environments hamper the ability of robotic systems to understand their surroundings.
Difficulty in understanding or reasoning about the surroundings lead to robotic systems failing to extract sufficent information to make automated 
informed decisions. In case of such failure to understand its surrounds, a robotic system can resort to human support via tele-operation or 
act dubiously based on the limited knowledge inferred by the robotic system. Thus, for a robotic system to successfully operate in natural environments, its critical for the system to be able to recognize objects despite unpredictable environmental conditions or noisy sensor measurements.

%================================================================================================================
\section{Noise in Sensor Measurements}

Sensors are designed to measure a physical quantity. This physical quantity is captured in form of a signal by the sensor.
The measurement reported by the sensor almost always does not match the real value of the physical quantity.
This error in the measured value is defined as the noise in measurement reported by the sensor.
The ubiquitous presence of noise in almost all sensor measurements has spurred a field of study in itself in the name of 
\emph{Filter Theory} \cite{haykin}. Filter theory deals with estimation of signals from such noisy data. 
If the source and nature of noise that affects measurements of a sensor can be modeled, then specialized
filters can be designed to recover the underlying signal from noisy sensor measurements.
The challenge here is in identifying the noise sources and modeling them. 
The sources of noise in sensor data can be manifold. An exhaustive discussion on sources of noise and methods to model them
is beyond the scope of this dissertion. In the remainder of this section, we will focus on specific sources of noise that affect 
imagery data collected by robots operating in natural environments (Section~\ref{sec:noise_sources}) and some filters that can 
help recover the underlying signal in these cases (Section ~\ref{sec:noise_filters}).

\subsection{Noise Sources}
\label{sec:noise_sources}

The sources of noise associated with an application need to be carefully analyzed before designing appropriate filters to mitigate the noise.
In the specific case of imaging applications using a camera sensor in natural environments, the various noise sources can be broadly divided
into \begin{enumerate*}[label=(\roman*)] \item noise inherent to the sensor, \item noise associated with data collection setup and \item noise introduced by the environment. \end{enumerate*} For instance in case of an underwater imaging application using an \gls{auv}, the noise associated with the imaging setup constitutes noise due to vibration or motion of the \gls{auv} that can affect the images captured by the camera mounted on the \gls{auv}. Additionally, the environmental parameters associated with deep sea environments could introduce noise which could further degrade the sensor measurements. Further details about the different noise sources is dicussed in the rest of this section.

In an imaging application, some noise is inherent to the camera sensor. A previous study \cite{irie} has analyzed the various constituents of noise 
in a \gls{ccd} video-camera. According the this study, the sources of noise in a camera can further be divided into 3 categories, namely, illumination-independent noise, illumination dependent noise and digital processing noise. After further analysis, this work suggests that there are 4 major noise sources that contribute to the camera sensor noise, out of which readout noise and fixed pattern noise are constant illumination independent noise sources. One of the factors that determine the value of readout noise and fixed pattern noise is the temperature of the sensor. The remining two primary contributing noise sources, photo-shot noise and photo-response non-uniformity noise are illumination-dependent noise sources. Its important to note that, illumination dependent noise sources imply that the value of noise is a function of the intensity value of the pixel. Modeling all the noise sources for different camera sensors poses a challenge in itself.

Another source of noise is the physical setup which holdes the camera. This setup could be an \gls{auv} or just a stationary imaging rig. Such physical structures that hold the camera can introduce noise in form of vibration or motion of the structure during imaging. Such motion could lead to out-of-focus or blurred pictures. There could also be cases where the physical setup can produce artifacts like shadows that could affect the sensor measurements. The few examples mentioned here are not all encompassing. Each imaging setup needs to be studied to identify the possible sources of noise it can introduce into the sensor measurements.

Environmental conditions are one of the chief sources of noise. There is a key difference between noise due to environmental conditions 
and other sources like sensor noise or the imaging setup noise: the former is relatively difficult to model due to wide range of variables
associated with environment. These environmental variables are fairly limited in controlled environments, but in case of natural environments
the number of variables are far higher. Furthermore the ability to predict or model the environemntal variables in natural
environemnts is far more challenging compared to controlled environments. To illustrate the variables associated with natural environments, lets
consider the case of imaging experiments in sub-sea environments. 
Some of the variables at play here are poor non-uniform illumination, absorbtion of light by water
and scattering of light by different particles in water. Each of these parameters can have considerable impact on the quality of the image actuired by
a camera sensor. Modeling these environment variable and accounting for the noise induced by them in the sensor measurements is critical to extract any useful
information from the sensor data.

Any object recognition method has to account for the different noise sources that can affect the sensor measurements. Especially in case of natural environments, environmental conditions typically act as major noise sources. 
In any case, its important to design appropriate ways to mitigate the effect of noise 
in the sensor measurements before useful information can be extracted. 
Even in the absense of accurate models of different noise sources, it is important to attempt to model the noise seen in the sensor data
and devise filters to extract the underlying signal from the recorded sensor measurements.

\subsection{Noise Filtering}
\label{sec:noise_filters}

One of the prerequisites for extracting information from noisy sensor data, is modeling the noise sources followed by filter design.
Model of the noise induced by the sensor is often provided by the manufacturer as a part of the sensor specifications. 
This allows to the designer integrating the sensor into a custom setup to skip the effort need to discover the characteristics of the sensor. 
However the noise induced by the setup is unique to each system and hence needs to be analyzed to identify the characteristics of the noise.
Once a model is identified, the filter design stage involves designing a filter that can recover the signal from recorded sensor measurements.

The task of filtering noise induced by the environmental variable is more complex relative to the inherent sensor noise or the setup noise.
The reason is due to the difficulty in modeling the noise. In case of underwater imaging apparatus, understanding the physics of 
light propagation involving phenomenon like absorption and scattering is required. Some proposed models \cite{garcia, ahlen} tries to 
explain light propagation in water and also suggest filter models that can correct illumination and color in noisy underwater images. A more detailed survey
by Jaffe \cite{jaffe} describes different existing filter models available to deal with noise in underwater images.
In most cases modeling all the parameters of the environment is not tractable, hence identifying the  dominant noise sources or simply identifying the nature of noise affecting the images are possible alternatives.
For instance, in the scallop recognition work \cite{prasanna_aslo}, the \gls{auv} images used were corrupted by speckle noise,
hence a median filter \cite{despeckle} was used to minimize noise.

Since extracting useful information from sensor data is essential for object recognition, noise filters constitute a core component of object recognition systems. The first stage in noise filtering constitutes identifying noise sources and modeling them. Accurate modeling of noise sources in often challenging, hence most systems use simplified models that where only dominant noise sources are considered. Since there are several filtering mechanisms available, filter design often involves human intuition to pick appropriate filters that can handle the noise pattern seen. Ultimately, the noise filtering allows distilling useful information for informed descision making.

%================================================================================================================
\section{Object Recognition in Natural Environments}

For an object recognition framework to be effective in natural environments with unpredictable conditions, it
should be robust to noise and variations in environmental conditions. 
To avoid dealing with unceratinities in environmental conditions, researchers tend to specialized object recognition techniques that work in certain controlled conditions. In some instances even the sensing apparatus used can be explicitly designed to detect a certain organism as in the case of plankton 
recognitions systems \cite{mcgavin_plankton, stelzer_rotifier}. Such techniques that are highly specialized to solve a specific problem 
and do not transfer to other application domains. Another instance of object recognition in controlled conditions is the scallop recognition system in artificial scallop beds \cite{enomoto9,enomoto10}, where a series of stationary camera are used to perform object recognition. The object recognition systems built on the assumption of controlled environmental conditions, generally do not translate well to natural environments that exhibit wide variation in environmental conditions.

Building specialized object recognition frameworks might not translate between different application domain. At the same time building a generalized object 
recognition method that can accomodate wide variations in environmental conditions and also support recognition of different object classes is challenging. 
One solution to this problem is the use of Multi-layered object recognition frameworks. Multi-layered object recognition frameworks with dedicated modules for dealing with different sub-problems like filtering and hypothesis testing allow easy customization of layers based on application requirements. 
Multi-layered frameworks allow researchers to configure specialized layers that are custom designed for their object recognition problem. The scallop
recognition framework \cite{prasanna_aslo, prasanna_igi} offers one such multi-layered framework. Another interesting example is the set of underwater object recognition tools \cite{schoening} used for recognising organisms like sea-anemones.

In conclusion, layered object recognition frameworks offer a flexible solution to researchers to solve automated object recognition problem. Customizing a multi-layered object recognition framework to work with different specialized problem amount to picking the right layers that would be effective to solve the specific problem. The layers used can be adaptions of available computer vision or machine learning tools. For cases where there is no available solution to solve a certain sub-problem, a researcher can engineer a multilayered framework with existing tools along with a custom designed sub-layer to deal with the specialized sub-problems.

%================================================================================================================
\section{Object Recognition as a path to Robot Autonomy}

Object recognition capability allows a robotic system to identify and label the different components in its environment. Such understanding of individual objects in its surrounding is required to build a semantic model that captures the relationship between the different components in an environment.
Cognitive reasoning relies on such semantic models to determine the best possible action for an agent to undertake given its knowledge about the state of the environment. Thus we can conclude that object recognition capabilities are essential to build robotic systems capable of automated informed descision making.

The task of object recognition and understanding the state of the environment becomes challenging in the presence of noise. Sensor measurements
that are supposed to measure the state of the environment could be corrupted due to the presence of noise. In order to avoid being misled by bad measurements,
a robotic agent needs to employ noise filters to extract the underlaying signal from sensor measurements. Since sensor measurements in natural environments are generally corrupted by noise induced by various environmental factors, noise filters become a core component of the perception system that aggregates sensor measurements to gain knowledge about the state of the environment. Building accurate models of the surrounding despite the presence of noise is key to the success of a robot agent that is intended to operate autonomously in natural environments.

In conclusion, object recognition capabilites, with robustness to noise, is required to build systems that operate in natural environemnts. Object recognition coupled with an ability to model and reason about the state of the environment allows a robotic system to make automated informed descisions. Automated informed descision making in conjunction with automous actuation paves the way for a robotic system to be fully autonomous. Fully autonomous systems can act independently without any human support in remote natural environments. Such systems can ease the strain on human work force by taking up tasks that are physically challenging or risky for a human to perform.

%================================================================================================================
\section{Approach Overview}

Since we have established that object recognition in noisy environments is critical for robot autonomy, the rest
of this disseration will propose a series of techniques designed to solve the object recognition problem in noisy environments.
Furthermore, since operation in natural environment is typically characterized by noisy sensor measurements, we choose
underwater object recognition as the primary domain to conduct the experimental vaidation for all the approaches discussed in this disseratation.
The rest of this section will offer a brief overview of the different object recognition techniques developed as a part of this 
dissertation along with insights on the problems they address.

Recognizing submerged subway cars from seabed images was the first application that initiated the need for 
an object recognition technique capable of operating in noisy seabed images. Since recognizing subway cars can be reduced 
to detecting rectangles, eigen-ratio based shape descriptors with in-built \gls{rst} invariance was the candidate technique tested
to solve this specific object recognition problem. Eigen-value based shape descriptors were successful in detecting 
simple shapes like rectangles from images.
However several shortcomings of eigen-value shape descriptors with regards to operating in noisy domains and dealing with objects with complex shape profiles were exposed. Chapter~\ref{chap:eigen} of this disseratation offers a detailed treatment of the eigen value shape descriptors and the results of the subway car recognition problem they were tested on.

When the scope of the object recognition problem was expanded from simple shapes like rectangles to underwater organisms characterized by complex profiles,
the shortcomings of eigen-value shape descriptors became more apparent. The primary application domain that drove the design of this object recognition system 
was scallop recognition system 
capable of automated scallop enumeration to support benthic survey efforts through images collected from an \gls{auv}. To support this 
scallop population assessment effort,
a multi-layered object recognition system capable of recognising objects from noisy natural images was proposed. The method was capable of detecting 60-75\% of scallops. This method was expressly designed to deal with noise introduced by non-uniform lighting, low resolution images and large levels of speckle noise, that previous scallop recognition efforts were not equipped to handle. Chapter~\ref{chap:scallop_recog} talks in detail about this multi-layered object recognition framework.

Despite the ability of the multi-layered object recognition framework proposed in \ref{chap:scallop_recog} to detect objects from noisy images, there were 
several instances of false positives in the ensuing detections. This prompted the need for a classification technique that can recognize object will lesser
false positives. One way to accomplish this was to merge information multiple views of an object before determining its identity. The details involved in this
multi-view object recognition approach is discussed in Chapter~\ref{chap:dist_des}.

During the course of development of these object recognition algorithms, the need for a low-cost research platform 
that can be used as a test bed to evaluate different object recognition algorithms was realized.
In response to this, CoopROV, a low cost underwater \gls{rov} was developed. CoopROV's specifications and 
design procedure is discussed in Chapter~\ref{cooprov}.

%================================================================================================================
\section{Dissertation Organization}

The rest of this dissertation is organized as follows 
\begin{enumerate*}[label=(\roman*)] 
  \item Chapter~\ref{chap:eigen} discusses the eigen-value shape descriptors and the subway car detection problem they were evaluated on.
  \item The multi-layered object recognition technique developed in response to the requirement automated scallop survey effort 
  is discussed Chapter~\ref{chap:scallop_recog}.
  \item This is followed by the muli-view object recognition technique that allows to combine information from multiple views 
  of a target object to decrease false positives seen in the multi-layered object recognition technique.
  \item Chapter~\ref{sec:cooprov} provides details on the underwater \gls{rov} designed as a research to act as a test bed for object recognition algorithms.
  \item Finally, Chapter~\ref{chap:conclusion} expresses the insights gleaned during the course of development of the different object recognition techniques designed to deal with noisy natural images and possible future directions that can be explored.
\end{enumerate*}

%================================================================================================================
\printglossary[type=\acronymtype]                  
\include{bibtex}   % This file (bibtex.tex) contains the text
                   % for a bibliography if using BibTeX with
                   % sample.bib
\end{document}


