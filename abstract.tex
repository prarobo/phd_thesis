Building autonomy into robotic systems enables them to operate 
unsupervised over remote and potentially dangerous domains, ultimately reducing the strain on human workforce.
Object recognition is an important trait required for a robotic system to achieve autonomy.
The task of object recognition is essentially understanding and labeling the different components in a robot's environment. This task can get complicated for robots that operate in unstructured natural environments, like forests or deep sea, due to noise in sensor measurements that could potentially affect their perception of the world. To avoid being misled by noise in sensor measurements, robots need to possess robust object recognition capabilites that can handle noise in measurements. Such robust object recognition valuable for processing large natural image datasets. One such example is the underwater image datasets collected by marine scientists and oceanographers using robotic systems like \gls{auv}s. The objective here is to analyse these datasets to understand natural phenomenon and  recognize organisms. Sifting through such \emph{big} datasets, ranging millions of images, to make inferences is growing to be big challenge to the research community, hence motivating the need for automated object recongition and image analysis tools.
This dissertation focusses on object recognition techniques capable of operating in noisy natural environments.
A series underwater object recognition  problems have been solved as means to validate the developed object recognition algorithms. 
Each technique was developed to complement the shortcomings of the existing tools available to the research community. 

To start with, eigen-value based shape descriptors were tasked to solve the subway car recognition problem. Despite their success in solving this problem, their inability to capture the texture in objects among other things lead to the development of an elaborate multi-layered object recognition architecture. This multi-layered architecture was casted as an automated scallop recognition solution. To improve the machine learning classifier of this multi-layered framework and minimize false positives, a multi-view approach is proposed. This multi-view approach combines histogram-based global cues from a series of images of a target captured from different heights to construct a classifier. This classifier encodes the variation in appearance of specimens by considering the heights as an additional dimension in the feature space of this machine learning method. This method was successful in classifying all specimens in the available dataset. In addition to the developed object recognition methods, a \gls{rov} named CoopROV was designed to support testing of underwater object recognition experiments.
